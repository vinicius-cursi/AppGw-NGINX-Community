# Configura√ß√£o de Cluster NGINX HA com Balanceamento Avan√ßado

Este documento detalha a configura√ß√£o completa para um cluster de NGINX em Alta Disponibilidade (HA) no modelo Ativo/Passivo, utilizando **Keepalived** para failover autom√°tico.

A configura√ß√£o inclui regras avan√ßadas de balanceamento de carga:
* **Persist√™ncia de Sess√£o**: Garante que um usu√°rio seja direcionado sempre para o mesmo servidor backend.
* **Balanceamento por Peso**: Distribui mais tr√°fego para os servidores das aplica√ß√µes mais cr√≠ticas.
* **Health Checks Passivos**: Remove automaticamente um servidor do balanceamento ap√≥s 5 falhas de conex√£o e o adiciona de volta quando o servi√ßo se normaliza.

---

## Diagrama da Arquitetura

O diagrama abaixo ilustra o fluxo de tr√°fego, desde o cliente at√© as aplica√ß√µes backend, passando pelo cluster NGINX HA.

```mermaid
graph TD
    subgraph "Rede Externa"
        A[Cliente Browser] -- DNS aponta para o VIP --> B((üåê<br>IP Virtual / VIP<br>192.168.1.10))
    end

    subgraph "Rede Corporativa / VPN"
        ADMIN[üíª Administrador] -- Acesso Seguro --> B
    end

    subgraph "Cluster NGINX HA (Ativo/Passivo)"
        style NGINX2 fill:#f9f,stroke:#333,stroke-width:2px,stroke-dasharray: 5 5

        subgraph "Servidor Prim√°rio"
            NGINX1(üü¢ NGINX-01<br><b>Estado: MASTER</b>)
        end
        subgraph "Servidor Secund√°rio"
            NGINX2(üü° NGINX-02<br><b>Estado: BACKUP</b>)
        end

        B -- Fluxo de Tr√°fego P√∫blico --> NGINX1
        ADMIN -- Acesso √† /nginx_status --> NGINX1
        NGINX1 <.-> |VRRP Heartbeat<br>via Keepalived| NGINX2
    end

    subgraph "Rede Interna (Servidores Backend)"
        C1(Upstream: app01_backend)
        C2(Upstream: app02_backend)
        C3(Upstream: app03_backend)
        C4(Upstream: app04_backend)
        C5(Upstream: app05_backend)
        C6(Upstream: lbprobe_backend)
    end

    NGINX1 -- proxy_pass (/app01) --> C1
    NGINX1 -- proxy_pass (/app02) --> C2
    NGINX1 -- proxy_pass (/app03) --> C3
    NGINX1 -- proxy_pass (/app04) --> C4
    NGINX1 -- proxy_pass (/app05) --> C5
    NGINX1 -- proxy_pass (/lbprobe) --> C6
````

-----

## Passo 1: Configura√ß√£o do NGINX
Este arquivo deve ser **id√™ntico em ambos os servidores NGINX** (NGINX-01 e NGINX-02). Ele cont√©m a l√≥gica de roteamento, balanceamento e os health checks passivos.

**Arquivo:** `/etc/nginx/conf.d/mydomain.conf`

```nginx
# --- Upstreams (Pools de Servidores Backend) ---
#
# Diretivas utilizadas:
# least_conn: Envia novas requisi√ß√µes para o servidor com o menor n√∫mero de conex√µes ativas.
# sticky cookie: Garante que um cliente permane√ßa no mesmo servidor durante sua sess√£o (requer m√≥dulo extra).
# max_fails=5: Marca um servidor como indispon√≠vel ap√≥s 5 tentativas de conex√£o falhas.
# fail_timeout=30s: Ap√≥s ser marcado como indispon√≠vel, o NGINX n√£o tentar√° se conectar a ele por 30 segundos.
#                   Depois desse tempo, ele volta a receber tr√°fego gradualmente.
# weight: Define a prioridade de tr√°fego para cada aplica√ß√£o.

upstream app01_backend {
    least_conn;
    sticky cookie srv_id expires=1h domain=.mydomain.com path=/app01/;
    server 192.168.1.101:5000 weight=4 max_fails=5 fail_timeout=30s;
    server 192.168.1.102:5000 weight=4 max_fails=5 fail_timeout=30s;
    server 192.168.1.103:5000 weight=4 max_fails=5 fail_timeout=30s;
    server 192.168.1.104:5000 weight=4 max_fails=5 fail_timeout=30s;
}

upstream app02_backend {
    least_conn;
    sticky cookie srv_id expires=1h domain=.mydomain.com path=/app02/;
    server 192.168.1.101:5001 weight=4 max_fails=5 fail_timeout=30s;
    server 192.168.1.102:5001 weight=4 max_fails=5 fail_timeout=30s;
    server 192.168.1.103:5001 weight=4 max_fails=5 fail_timeout=30s;
    server 192.168.1.104:5001 weight=4 max_fails=5 fail_timeout=30s;
}

upstream app03_backend {
    least_conn;
    sticky cookie srv_id expires=1h domain=.mydomain.com path=/app03/;
    server 192.168.1.101:5002 weight=3 max_fails=5 fail_timeout=30s;
    server 192.168.1.102:5002 weight=3 max_fails=5 fail_timeout=30s;
    server 192.168.1.103:5002 weight=3 max_fails=5 fail_timeout=30s;
    server 192.168.1.104:5002 weight=3 max_fails=5 fail_timeout=30s;
}

upstream app04_backend {
    least_conn;
    sticky cookie srv_id expires=1h domain=.mydomain.com path=/app04/;
    server 192.168.1.101:5003 weight=2 max_fails=5 fail_timeout=30s;
    server 192.168.1.102:5003 weight=2 max_fails=5 fail_timeout=30s;
    server 192.168.1.103:5003 weight=2 max_fails=5 fail_timeout=30s;
    server 192.168.1.104:5003 weight=2 max_fails=5 fail_timeout=30s;
}

upstream app05_backend {
    least_conn;
    sticky cookie srv_id expires=1h domain=.mydomain.com path=/app05/;
    server 192.168.1.101:5004 weight=1 max_fails=5 fail_timeout=30s;
    server 192.168.1.102:5004 weight=1 max_fails=5 fail_timeout=30s;
    server 192.168.1.103:5004 weight=1 max_fails=5 fail_timeout=30s;
    server 192.168.1.104:5004 weight=1 max_fails=5 fail_timeout=30s;
}

upstream lbprobe_backend {
    least_conn;
    server 192.168.1.101:5006;
    server 192.168.1.102:5006;
    server 192.168.1.103:5006;
    server 192.168.1.104:5006;
}

# --- Bloco do Servidor ---
server {
    listen 80;
    server_name www.mydomain.com;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl http2;
    server_name www.mydomain.com;

    ssl_certificate /etc/nginx/ssl/mydomain.pem;
    ssl_certificate_key /etc/nginx/ssl/mydomain.pem;
    ssl_password_file /etc/nginx/ssl/ssl_pass.txt;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_prefer_server_ciphers on;
    ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256';
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    # --- Roteamento das Aplica√ß√µes ---
    location /app01/ { proxy_pass http://app01_backend; }
    location /app02/ { proxy_pass http://app02_backend; }
    location /app03/ { proxy_pass http://app03_backend; }
    location /app04/ { proxy_pass http://app04_backend; }
    location /app05/ { proxy_pass http://app05_backend; }
    location /lbprobe/ { proxy_pass http://lbprobe_backend; }

    # --- Bloco para a P√°gina de Status ---
    location /nginx_status {
        stub_status;
        allow 10.0.0.0/8;
        allow 192.168.0.5;
        deny all;
    }
}
```

-----

## Passo 2: Configura√ß√£o do Keepalived para HA

Instale o Keepalived em ambos os servidores NGINX (`sudo apt install keepalived` ou `sudo yum install keepalived`).

#### **1. Script de Verifica√ß√£o do NGINX**

Crie este script em **ambos os servidores**. O Keepalived o usar√° para garantir que o processo do NGINX est√° ativo. Se n√£o estiver, ele iniciar√° o failover.

Este conte√∫do deve ser salvo no arquivo `/etc/keepalived/check_nginx.sh` em **ambos** os servidores. Depois, torne-o execut√°vel com `sudo chmod +x /etc/keepalived/check_nginx.sh`.

```bash
#!/bin/bash
# Verifica se o processo do NGINX existe
if pgrep nginx > /dev/null; then
    exit 0 # Sucesso, NGINX est√° rodando
else
    exit 1 # Falha, NGINX n√£o est√° rodando
fi
```

Torne o script execut√°vel: `sudo chmod +x /etc/keepalived/check_nginx.sh`

-----

### **2. Configura√ß√£o do Keepalived - Servidor NGINX-01 (MASTER)**

Este conte√∫do deve ser salvo no arquivo `/etc/keepalived/keepalived.conf` apenas no **servidor NGINX-01 (MASTER)**.

**Arquivo:** `/etc/keepalived/keepalived.conf`

```nginx
# Bloco global
global_defs {
   router_id NGINX_MASTER
}

# Script para monitorar o NGINX
vrrp_script check_nginx {
    script "/etc/keepalived/check_nginx.sh"
    interval 2  # Executar a cada 2 segundos
    weight 50   # Adicionar 50 √† prioridade se o script for bem-sucedido
}

# Inst√¢ncia VRRP para gerenciar o IP Virtual
vrrp_instance VI_1 {
    state MASTER                # Este √© o servidor PRIM√ÅRIO
    interface ens160            # IMPORTANTE: Altere para sua interface de rede (ex: eth0)
    virtual_router_id 51        # Deve ser o mesmo em ambos os servidores
    priority 150                # A prioridade mais alta se torna MASTER

    advert_int 1                # An√∫ncios VRRP a cada 1 segundo

    authentication {
        auth_type PASS
        auth_pass sua_senha_secreta # Altere e use a mesma senha nos dois servidores
    }

    # O IP Virtual (VIP) que ser√° compartilhado
    virtual_ipaddress {
        192.168.1.10/24         # IMPORTANTE: Altere para o VIP desejado
    }

    # Associar o script de monitoramento
    track_script {
        check_nginx
    }
}
```

-----

### **3. Configura√ß√£o do Keepalived - Servidor NGINX-02 (BACKUP)**

Este conte√∫do deve ser salvo no arquivo `/etc/keepalived/keepalived.conf` apenas no **servidor NGINX-02 (BACKUP)**.

**Arquivo:** `/etc/keepalived/keepalived.conf`

```nginx
# Bloco global
global_defs {
   router_id NGINX_BACKUP
}

# Script para monitorar o NGINX (id√™ntico ao MASTER)
vrrp_script check_nginx {
    script "/etc/keepalived/check_nginx.sh"
    interval 2
    weight 50
}

# Inst√¢ncia VRRP para gerenciar o IP Virtual
vrrp_instance VI_1 {
    state BACKUP                # Este √© o servidor SECUND√ÅRIO
    interface ens160            # IMPORTANTE: Deve ser a mesma interface do MASTER
    virtual_router_id 51        # Deve ser o mesmo do MASTER
    priority 100                # Prioridade menor o torna um BACKUP

    advert_int 1

    authentication {
        auth_type PASS
        auth_pass sua_senha_secreta # Deve ser a mesma senha do MASTER
    }

    # O mesmo IP Virtual do MASTER
    virtual_ipaddress {
        192.168.1.10/24
    }

    track_script {
        check_nginx
    }
}
```

Ap√≥s criar os arquivos, inicie e habilite o servi√ßo Keepalived em ambos os servidores:

```bash
sudo systemctl start keepalived
sudo systemctl enable keepalived
```
